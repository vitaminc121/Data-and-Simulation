#1.1 load packages
library(readxl)
#1.2 prepare the data which has been selected
data1 <- read.csv("proteins_data.csv")
# split data1 into train sub-data and validation sub-dara
train_sub <- sample(nrow(data1),7/10*nrow(data1))
train_data <- data1[train_sub,]
test_data <- data1[-train_sub,]

# 2.1 xgboot algorithm 
#install.packages("xgboost")
library(xgboost)
library(Matrix)

### data pretreatment for train data
# change independent variables into matrix
traindata1 <- data.matrix(train_data[,c(2:10)])
# change 'traindata1' into sparse matrix by using Matrix function
traindata2 <- Matrix(traindata1,sparse = T)
# get respondents
traindata3 <- train_data[,11]
# list the independent variables and respondents
traindata4 <- list(data = traindata2,label = traindata3)
# construct object for xgb.DMatrix,the object is sparse matrix
dtrain <- xgb.DMatrix(data = traindata4$data,label = traindata4$label)

### data pretreatment for test data
# change independent variables into matrix
testset1 <- data.matrix(test_data[,c(2:10)])
# change 'traindata1' into sparse matrix by using Matrix function
testset2 <- Matrix(testset1,sparse = T)
## get respondents
testset3 <- test_data[,11]
# list the independent variables and respondents
testset4 <- list(data = testset2,label=testset3)
# construct object for xgb.DMatrix,the object is sparse matrix
dtest <- xgb.DMatrix(data = testset4$data,label = testset4$label)
#  model
xgb <- xgboost(data = dtrain,max_depth=6, eta=0.5,  objective='binary:logistic', nround=25)

# predict in test data
pre_xgb <- round(predict(xgb, newdata = dtest))
# output the confusion matrix
table(test_data$depression,pre_xgb,dnn=c("Dep","nDep"))

# plot ROC and calculate AUC
library(pROC)
xgboost_roc <- roc(test_data$depression,as.numeric(pre_xgb))
plot(xgboost_roc,print.auc=TRUE, auc.polygon=TRUE,grid=c(.1,.2),
     grid.col=c("green","red"),max.auc.polygon=TRUE,
     auc.polygon.col="skyblue",print.thres = TRUE,
     main = "performance of xgboost model")

# 2.2 BPNN model
# load packages
library(grid)
library(MASS)
library(neuralnet)
# model1
net <- neuralnet(depression ~ P558+P48637+Q14676+AA87WSY6+O15144+J3QRN2+Q99784+B7ZKJ8+AA3B3IRN5,
                 data = train_data,
                 hidden = 1,threshold = 0.005,learningrate = 0.1,
                 algorithm = "rprop+",err.fct = "sse",
                 act.fct = "logistic")
#print(net)
# plot
#plot(net)
# predict in test data
pre_net <-  round(predict(net, newdata = test_data))
# output the confusion matrix
table(test_data$depression,pre_net,dnn=c("Dep","nDep"))

# plot ROC and calculate AUC
library(pROC)
net_roc <- roc(test_data$depression,as.numeric(pre_net))
plot(net_roc,print.auc=TRUE, auc.polygon=TRUE,grid=c(.1,.2),
     grid.col=c("green","red"),max.auc.polygon=TRUE,
     auc.polygon.col="skyblue",print.thres = TRUE,
     main = "performance of BPNN model")

# 2.3 SVM model
# load packages
library(e1071)
# pretreatment for data
train_data$depression <- as.factor(train_data$depression)
test_data$depression <- as.factor(test_data$depression)
# model
svm_model <- svm(depression ~  P558+  P48637+ Q14676+ AA87WSY6+ O15144 +J3QRN2+   Q99784+B7ZKJ8+AA3B3IRN5,
                 data = train_data,
                 type = "C", kernel = "radial")
# predict in test data
pre_svm <-  predict(svm_model, newdata = test_data)
# intergrate true value and predict value
obs_p_svm <-  data.frame(prob=pre_svm,obs=test_data$depression)
# output the confusion matrix
table(test_data$depression,pre_svm,dnn=c("Dep","nDep"))

# plot ROC and calculate AUC
library(pROC)
svm_roc <- roc(test_data$depression,as.numeric(pre_svm))
plot(svm_roc,print.auc=TRUE, auc.polygon=TRUE,grid=c(.1,.2),
     grid.col=c("green","red"),max.auc.polygon=TRUE,
     auc.polygon.col="skyblue",print.thres = TRUE,
     main = "performance of SVM model")

# 2.4 randomForest model
# library package
library(randomForest)
# pretreatment for data
train_data$depression <- as.factor(train_data$depression)
test_data$depression <- as.factor(test_data$depression)
# model
rf_model <- randomForest(depression ~  P558+  P48637+ Q14676+ AA87WSY6+ O15144 +J3QRN2+   Q99784+B7ZKJ8+AA3B3IRN5,
                 data = train_data,
                 ntree = 500,
                 ntry = 3,
                 importance = TRUE,
                 proximity = TRUE)
# check the importance of independent variables
rf_model$importance
varImpPlot( rf_model,main = "variable importance")
# predict in test data
pre_rf <-  predict(rf_model, newdata = test_data)
# intergrate true value and predict value
obs_p_rf <-  data.frame(prob=pre_rf,obs=test_data$depression)
# output the confusion matrix
table(test_data$depression,pre_rf,dnn=c("Dep","nDep"))
# plot ROC and calculate AUC
library(pROC)
rf_roc <- roc(test_data$depression,as.numeric(pre_rf))
plot(rf_roc,print.auc=TRUE, auc.polygon=TRUE,grid=c(.1,.2),
     grid.col=c("green","red"),max.auc.polygon=TRUE,
     auc.polygon.col="skyblue",print.thres = TRUE,
     main = "performance of rf model:mtry=3,ntree=500")

# 2.5 logistic regression
# model
lg_model <- glm(depression ~  P558+  P48637+ Q14676+ AA87WSY6+ O15144 +J3QRN2+   Q99784+B7ZKJ8+AA3B3IRN5,
                 data = train_data,
                 family = binomial(link = "logit"))

# predict in test data
pre_lg <-  predict(lg_model, newdata = test_data)
# intergrate true value and predict value
obs_p_lg <-  data.frame(prob=pre_lg,obs=test_data$depression)
# output the confusion matrix
table(test_data$depression,pre_lg,dnn=c("Dep","nDep"))
# plot ROC and calculate AUC
library(pROC)
lg_roc <- roc(test_data$depression,as.numeric(pre_lg))
plot(lg_roc,print.auc=TRUE, auc.polygon=TRUE,grid=c(.1,.2),
     grid.col=c("green","red"),max.auc.polygon=TRUE,
     auc.polygon.col="skyblue",print.thres = TRUE,
     main = "performance of lg model")

#  rocs of different models in one plotc-1
plot(xgboost_roc,col="red")
plot(net_roc,add = TRUE, col = 'green')
plot(svm_roc,add = TRUE, col = 'black')
plot(rf_roc,add = TRUE, col =  'blue')
plot(lg_roc,add = TRUE, col =  'pink')
legend("bottomright",
       title = "rocs of different models",c("xgboost","BPNN","SVM","RF","LR"),
       legend = c("xgboost","BPNN","SVM","RF","LR"),
       col = c("red","green","black","blue","pink"),
       lty = 1,lwd =2)
       
# rocs of different models in one plotc-2
library(pROC)
library(ggplot2)
#g <- ggroc(xgboost_roc)
#g + theme_minimal() + ggtitle("ROCS")+
#  geom_segment(aes(x=1,xend=0),y=0,yend=1,color = "red",linetype = 6)
#gl <- ggroc(xgboost_roc, legacy.axes = TRUE)
#gl
#gl + xlab("1-specificity") + ylab("sensitivity") + 
  geom_segment(aes(x = 0, xend = 1, y = 0, yend = 1), color="darkgrey", linetype="dashed")

g2 <- ggroc(list(xGboost=xgboost_roc, BPNN=net_roc, SVM=svm_roc,Rf=rf_roc,
                 LG=lg_roc))
g2 


